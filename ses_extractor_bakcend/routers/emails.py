# ses_extractor_bakcend/routers/emails.py
from fastapi import APIRouter, HTTPException,Depends
from fastapi.responses import JSONResponse
from fastapi import Request
import os
import re
import json
from pydantic import BaseModel
import logging
from datetime import datetime, timedelta, timezone
from dotenv import load_dotenv
from supabase import create_client, Client
from typing import Set
from utils.emails import fetch_ses_emails
from utils.gemini_and_db import parse_emails_with_gemini, send_to_api
from services.auth_service import AuthService
from middleware.auth import get_current_user
from typing import Union
from typing import Optional
from typing import Dict
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

# åˆæœŸåŒ–
router = APIRouter()
auth_service = AuthService()
load_dotenv()
security = HTTPBearer()

# è¨­å®š
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_API_KEY = os.getenv("SUPABASE_KEY")
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")
GMAIL_API_URL = "https://gmail.googleapis.com/gmail/v1/users/me/messages"

supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_KEY")
)

# ãƒ­ã‚°è¨­å®š
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

class RawEmailData(BaseModel):
    body: str
    headers: Dict[str, str]

class RawEmailResponse(BaseModel):
    success: bool
    data: RawEmailData



def get_parsed_message_ids() -> Set[str]:
    from supabase import create_client
    supabase = create_client(SUPABASE_URL, SUPABASE_API_KEY)
    # ses_projectsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å…¨ã¦ã®message_idã‚’å–å¾—
    result = supabase.table("ses_projects").select("message_id").execute()
    # ç©ºã§ãªã„message_idã‚’æŠ½å‡ºã—ã‚»ãƒƒãƒˆã«å¤‰æ›
    ids = set(item["message_id"] for item in result.data if item.get("message_id"))
    return ids


# SESãƒ¡ãƒ¼ãƒ«å–å¾—API
@router.get("/fetch_emails")
async def fetch_emails(user_email: str = Depends(get_current_user)):
    """SESãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—"""
    try:
        access_token = auth_service.get_valid_token(user_email)
        emails = fetch_ses_emails(access_token)
        logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_email} ãŒ {len(emails)} ä»¶ã®ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—")
        return {"emails": emails}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ãƒ¡ãƒ¼ãƒ«å–å¾—å¤±æ•—: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ãƒ¡ãƒ¼ãƒ«å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
        )
    
# å…¨ã¦ã®ãƒ¡ãƒ¼ãƒ«ã‚’è§£æã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
@router.post("/parse_and_save_all_emails")
async def parse_and_save_all_emails(user_email: str = Depends(get_current_user)):
    try:
        # ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—
        access_token = auth_service.get_valid_token(user_email)
        ses_emails = fetch_ses_emails(access_token)
        total_fetched = len(ses_emails)
        logging.info(f"ğŸ“¥ å–å¾—ã—ãŸãƒ¡ãƒ¼ãƒ«ç·æ•°: {total_fetched}")

        # æ—¢ã«è§£ææ¸ˆã¿ã®message_idã‚’å–å¾—
        parsed_ids = get_parsed_message_ids()
        logging.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®è§£ææ¸ˆã¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(parsed_ids)}")

        # æœªè§£æã®ãƒ¡ãƒ¼ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        unparsed_emails = [email for email in ses_emails if email.get("id") not in parsed_ids]
        logging.info(f"ğŸ§¹ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®æœªè§£æãƒ¡ãƒ¼ãƒ«æ•°: {len(unparsed_emails)}")
        logging.info(f"â™»ï¸ é‡è¤‡ï¼ˆè§£ææ¸ˆã¿ï¼‰ãƒ¡ãƒ¼ãƒ«æ•°: {total_fetched - len(unparsed_emails)}")

        # æ–°ã—ã„ãƒ¡ãƒ¼ãƒ«ãŒãªã„å ´åˆ
        if not unparsed_emails:
            logging.info("âœ… è§£æãŒå¿…è¦ãªæ–°ã—ã„ãƒ¡ãƒ¼ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")
            return JSONResponse(content={
                "status": "success", 
                "processed_count": 0, 
                "message": "è§£æãŒå¿…è¦ãªæ–°ã—ã„ãƒ¡ãƒ¼ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“",
                "logs": {
                    "total_fetched": total_fetched,
                    "parsed_count": len(parsed_ids),
                    "unparsed_count": 0,
                    "duplicate_count": total_fetched,
                    "processed_count": 0,
                    "message": "è§£æãŒå¿…è¦ãªæ–°ã—ã„ãƒ¡ãƒ¼ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“"
                }
            })

        # Geminiã§è§£æ
        email_data_list = parse_emails_with_gemini(unparsed_emails)

        # APIã«é€ä¿¡ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        send_to_api(email_data_list)

        logging.info(f"âœ… å®Ÿéš›ã«è§£æã—ã¦æ›¸ãè¾¼ã‚“ã ãƒ¡ãƒ¼ãƒ«æ•°: {len(email_data_list)}")

        return JSONResponse(content={
            "status": "success",
            "processed_count": len(email_data_list),
            "logs": {
                "total_fetched": total_fetched,
                "parsed_count": len(parsed_ids),
                "unparsed_count": len(unparsed_emails),
                "duplicate_count": total_fetched - len(unparsed_emails),
                "processed_count": len(email_data_list),
                "message": "è§£æã«æˆåŠŸã—ã¾ã—ãŸ"
            }
        })
    except Exception as e:
        logger.error(f"è§£æä¿å­˜ã«å¤±æ•—: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ãƒ¡ãƒ¼ãƒ«ã®è§£æä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            )
    

@router.get("/recent")
async def get_recent_emails():
    """
    è·å–è¿‘14å¤©çš„é‚®ä»¶æ•°æ®ï¼ˆä¿®å¤ç‰ˆï¼‰
    """
    try:
        # è·å–å½“å‰æ—¶é—´ï¼ˆå¸¦æ—¶åŒºä¿¡æ¯ï¼‰
        now = datetime.now(timezone.utc)
        five_days_ago = now - timedelta(days=14)

        logger.info(f"æŸ¥è¯¢æ—¶é—´èŒƒå›´: {five_days_ago.isoformat()} è‡³ {now.isoformat()}")



       # æŸ¥è¯¢æ•°æ®åº“
        response = supabase.table('ses_projects') \
            .select('*') \
            .gte('received_at', five_days_ago.isoformat()) \
            .order('received_at', desc=True) \
            .execute()

        # æ£€æŸ¥é”™è¯¯
        if hasattr(response, 'error') and response.error:
            logger.error(f"SupabaseæŸ¥è¯¢é”™è¯¯: {response.error}")
            raise HTTPException(status_code=500, detail="æ•°æ®åº“æŸ¥è¯¢å¤±è´¥")

        logger.info(f"æŸ¥è¯¢åˆ° {len(response.data)} æ¡è®°å½•")
        return {"emails": response.data}

    except Exception as e:
        logger.error(f"è·å–è¿‘æœŸé‚®ä»¶å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail="è·å–è¿‘æœŸé‚®ä»¶å¤±è´¥")




@router.get("/get_raw_email/{raw_email_id}", response_model=RawEmailResponse)
async def get_raw_email(
    raw_email_id: int,
    credentials: HTTPAuthorizationCredentials = Depends(security)
):
    try:
        jwt_token = credentials.credentials
        # await verify_jwt(jwt_token)

        # æŸ¥è¯¢æ•°æ®åº“
        logger.info(f"ğŸ” æŸ¥è¯¢åŸå§‹é‚®ä»¶ ID: {raw_email_id}")
        result = supabase.table('raw_emails').select('*').eq('id', raw_email_id).maybe_single().execute()

        if not result.data:
            raise HTTPException(status_code=404, detail="æŒ‡å®šIDçš„åŸå§‹é‚®ä»¶ä¸å­˜åœ¨")

        raw_email = result.data
        raw_data = raw_email.get("raw_data")
        
        # è®°å½•å®Œæ•´åŸå§‹æ•°æ®ï¼ˆè°ƒè¯•ç”¨ï¼‰
        logger.info(f"å®Œæ•´åŸå§‹æ•°æ®: {raw_data}")

        try:
            email_json = json.loads(raw_data)
        except json.JSONDecodeError:
            raise HTTPException(status_code=422, detail="åŸå§‹é‚®ä»¶æ•°æ®æ ¼å¼æ— æ•ˆ")

        # å…³é”®ä¿®æ­£ï¼šä»payloadå±‚çº§æå–æ•°æ®
        payload = email_json.get("payload", {})
        logger.info(f"Payloadæ•°æ®: {payload}")

        # å¤„ç†headers
        headers_list = payload.get("headers", [])
        headers_dict = {h.get("name"): h.get("value") for h in headers_list 
                       if isinstance(h, dict) and "name" in h and "value" in h}

        # å¤„ç†body
        body_data = payload.get("body", {}).get("data", "")
        
        # Base64è§£ç å¤„ç†
        if isinstance(body_data, str) and body_data.startswith("base64:"):
            import base64
            try:
                body_data = base64.b64decode(body_data[7:]).decode("utf-8")
              
            except Exception as e:
                logger.warning(f"Base64è§£ç å¤±è´¥: {str(e)}")
                body_data = "ï¼ˆæ­£æ–‡è§£ç å¤±è´¥ï¼‰"

        # æ„å»ºå“åº”
        response_data = {
            "success": True,
            "data": {
                "headers": headers_dict,
                "body": body_data,
                "metadata": {
                    "message_id": raw_email.get("message_id"),
                    "stored_at": raw_email.get("created_at")
                }
            }
        }

        logger.info(f"å¤„ç†åçš„å“åº”æ•°æ®: {response_data}")
        return response_data

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–åŸå§‹é‚®ä»¶å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨é”™è¯¯: {str(e)}")