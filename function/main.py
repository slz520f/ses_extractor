# main.py
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../')))
from gmail.fetch_emails import get_gmail_service, fetch_ses_emails
from parser.gemini_parser import GeminiParser
from db.db_writer import insert_email_to_db
from sheets.export_to_sheets import export_to_sheet,get_db_data
import base64
import json
from datetime import datetime
import logging
import re

from dotenv import load_dotenv
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def extract_headers(msg, name):
    """ãƒ¡ãƒ¼ãƒ«ãƒ˜ãƒƒãƒ€ã‹ã‚‰ç‰¹å®šã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º"""
    headers = msg.get('payload', {}).get('headers', [])
    for h in headers:
        if h.get('name', '').lower() == name.lower():
            return h.get('value', '')
    return ''

def extract_body(msg) -> str:
    """Gmailãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæœ¬æ–‡ã‚’æŠ½å‡º"""
    payload = msg.get('payload', {})
    
    # partsã‹ã‚‰æŠ½å‡ºã‚’è©¦ã¿ã‚‹
    parts = payload.get('parts', [])
    for part in parts:  
        if part.get('mimeType') == 'text/plain':
            data = part.get('body', {}).get('data', '')
            if data:
                return base64.urlsafe_b64decode(data).decode('utf-8')
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç›´æ¥body.dataã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
    if 'body' in payload and 'data' in payload['body']:
        return base64.urlsafe_b64decode(payload['body']['data']).decode('utf-8')
    
    return msg.get('snippet', '')

def format_datetime(gmail_date):
    """æ—¥ä»˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    try:
        # JSTãªã©ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³åã‚’å–ã‚Šé™¤ã
        gmail_date = re.sub(r'\s*\(.*\)$', '', gmail_date)
        return datetime.strptime(gmail_date, '%a, %d %b %Y %H:%M:%S %z').strftime('%Y-%m-%d %H:%M:%S')
    except Exception as e:
        logging.error(f"æ—¥ä»˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return datetime.now().strftime('%Y-%m-%d %H:%M:%S')

def main():
    logging.info("ğŸ” Gmailã‹ã‚‰ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—ã—ã¦ã„ã¾ã™...")
    
    try:
        # ã‚¹ãƒ†ãƒƒãƒ—1ï¼šGmailã‚µãƒ¼ãƒ“ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—ã—ã€ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—
        service = get_gmail_service()
        emails = fetch_ses_emails(service)
        
        if not emails:
            logging.warning("ğŸ“­ ä»Šæ—¥ã®ãƒ¡ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        logging.info(f"\nğŸ“© {len(emails)} ä»¶ã®è©²å½“ã™ã‚‹ãƒ¡ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        
        parser = GeminiParser()
        email_data_list = []  # å‡¦ç†æ¸ˆã¿ã®ãƒ¡ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ

        # ã‚¹ãƒ†ãƒƒãƒ—2ï¼šå„ãƒ¡ãƒ¼ãƒ«ã‚’å‡¦ç†
        for i, email in enumerate(emails, 1):
            logging.info(f"\n--- ãƒ¡ãƒ¼ãƒ« {i}/{len(emails)} ã‚’å‡¦ç†ä¸­ ---")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            subject = extract_headers(email, 'Subject')
            sender = extract_headers(email, 'From')
            date = format_datetime(extract_headers(email, 'Date'))
            body_text = extract_body(email)

            logging.info(f"ä»¶å: {subject}")
            logging.info(f"é€ä¿¡è€…: {sender}")
            logging.info(f"æ—¥ä»˜: {date}")
            
            if not body_text.strip():
                logging.warning("âš ï¸ æœ¬æ–‡ãŒç©ºã§ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue
            
            # å†…å®¹ã‚’è§£æ
            try:
                parsed = parser.parse_email(body_text)
                logging.info("è§£æçµæœ:")
                logging.info(json.dumps(parsed, indent=2, ensure_ascii=False))
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                email_data = {
                    'received_at': date,
                    'subject': subject,
                    'sender_email': sender,
                    'project_description': parsed.get('æ¡ˆä»¶å†…å®¹', ''),  # ãƒªã‚¹ãƒˆã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›
                    # 'required_skills': ', '.join(parsed.get('å¿…é ˆã‚¹ã‚­ãƒ«', [])),  # ãƒªã‚¹ãƒˆã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›
                    # 'optional_skills': ', '.join(parsed.get('å°šå¯ã‚¹ã‚­ãƒ«', [])),  # ãƒªã‚¹ãƒˆã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›
                    'required_skills': parsed.get('å¿…é ˆã‚¹ã‚­ãƒ«', []),
                    'optional_skills': parsed.get('å°šå¯ã‚¹ã‚­ãƒ«', []),
                    "location": parsed.get("å‹¤å‹™åœ°", ""),
                    "unit_price": parsed.get("å˜ä¾¡", ""),
                    'message_id': email.get('id')  
                }
                
                # å‡¦ç†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ›¸ãè¾¼ã‚€æº–å‚™
                email_data_list.append(email_data)
            
            except Exception as e:
                logging.error(f"âŒ ãƒ¡ãƒ¼ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        
        # ã‚¹ãƒ†ãƒƒãƒ—3ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€
        if email_data_list:
            logging.info("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ›¸ãè¾¼ã¿ã‚’é–‹å§‹ã—ã¾ã™...")
            for email_data in email_data_list:
                insert_email_to_db(email_data)
            logging.info("âœ… ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ›¸ãè¾¼ã¾ã‚Œã¾ã—ãŸ")
        
        # ã‚¹ãƒ†ãƒƒãƒ—4ï¼šãƒ‡ãƒ¼ã‚¿ã‚’Google Sheetsã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        if email_data_list:
            logging.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’Google Sheetsã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™...")

            
            SPREADSHEET_ID = os.getenv("SPREADSHEET_ID")

            if not SPREADSHEET_ID:
                print("âŒ SPREADSHEET_IDãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                print(f"ğŸ”§ ä½¿ç”¨ã™ã‚‹SPREADSHEET_ID: {SPREADSHEET_ID}")
                # SPREADSHEET_IDã‚’export_to_sheetã«æ¸¡ã™
                export_to_sheet(SPREADSHEET_ID)
            logging.info("âœ… ãƒ‡ãƒ¼ã‚¿ãŒGoogle Sheetsã«æ­£å¸¸ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸ")

    except Exception as e:
        logging.error(f"ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

if __name__ == "__main__":
    main()
