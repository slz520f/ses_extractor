# main.py
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../')))
from gmail.fetch_emails import get_gmail_service, fetch_ses_emails
from parser.gemini_parser import GeminiParser
from db.db_writer import insert_email_to_db
from sheets.export_to_sheets import export_to_sheet,get_db_data
import base64
import json
from datetime import datetime
import logging

from dotenv import load_dotenv
load_dotenv()

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def extract_headers(msg, name):
    """ä»é‚®ä»¶å¤´ä¸­æå–ç‰¹å®šå­—æ®µ"""
    headers = msg.get('payload', {}).get('headers', [])
    for h in headers:
        if h.get('name', '').lower() == name.lower():
            return h.get('value', '')
    return ''

def extract_body(msg) -> str:
    """ä»Gmailæ¶ˆæ¯ä¸­æå–çº¯æ–‡æœ¬æ­£æ–‡"""
    payload = msg.get('payload', {})
    
    # å°è¯•ä»partsä¸­æå–
    parts = payload.get('parts', [])
    for part in parts:  
        if part.get('mimeType') == 'text/plain':
            data = part.get('body', {}).get('data', '')
            if data:
                return base64.urlsafe_b64decode(data).decode('utf-8')
    
    # å›é€€æ–¹æ¡ˆï¼šç›´æ¥è§£ç body.data
    if 'body' in payload and 'data' in payload['body']:
        return base64.urlsafe_b64decode(payload['body']['data']).decode('utf-8')
    
    return msg.get('snippet', '')

def format_datetime(gmail_date):
    """æ ¼å¼åŒ–æ—¥æœŸ"""
    try:
        return datetime.strptime(gmail_date, '%a, %d %b %Y %H:%M:%S %z').strftime('%Y-%m-%d %H:%M:%S')
    except Exception as e:
        logging.error(f"æ—¥æœŸæ ¼å¼åŒ–å¤±è´¥: {str(e)}")
        return datetime.now().strftime('%Y-%m-%d %H:%M:%S')

def main():
    logging.info("ğŸ” æ­£åœ¨ä»Gmailè·å–é‚®ä»¶...")
    
    try:
        # ç¬¬ä¸€æ­¥ï¼šè·å– Gmail æœåŠ¡å¯¹è±¡å¹¶è·å–é‚®ä»¶
        service = get_gmail_service()
        emails = fetch_ses_emails(service)
        
        if not emails:
            logging.warning("ğŸ“­ æœªæ‰¾åˆ°ä»Šæ—¥é‚®ä»¶")
            return
        
        logging.info(f"\nğŸ“© æ‰¾åˆ° {len(emails)} å°ç¬¦åˆæ¡ä»¶çš„é‚®ä»¶")
        
        parser = GeminiParser()
        email_data_list = []  # ç”¨äºå­˜å‚¨æ‰€æœ‰å¤„ç†åçš„é‚®ä»¶æ•°æ®

        # ç¬¬äºŒæ­¥ï¼šå¤„ç†æ¯å°é‚®ä»¶
        for i, email in enumerate(emails, 1):
            logging.info(f"\n--- å¤„ç†é‚®ä»¶ {i}/{len(emails)} ---")
            
            # æå–å…ƒæ•°æ®
            subject = extract_headers(email, 'Subject')
            sender = extract_headers(email, 'From')
            date = format_datetime(extract_headers(email, 'Date'))
            body_text = extract_body(email)

            logging.info(f"ä¸»é¢˜: {subject}")
            logging.info(f"å‘ä»¶äºº: {sender}")
            logging.info(f"æ—¥æœŸ: {date}")
            
            if not body_text.strip():
                logging.warning("âš ï¸ æ­£æ–‡ä¸ºç©ºï¼Œè·³è¿‡")
                continue
            
            # è§£æå†…å®¹
            try:
                parsed = parser.parse_email(body_text)
                logging.info("è§£æç»“æœ:")
                logging.info(json.dumps(parsed, indent=2, ensure_ascii=False))
                
                # å‡†å¤‡æ•°æ®åº“æ•°æ®
                email_data = {
                    'received_at': date,
                    'subject': subject,
                    'sender_email': sender,
                    'project_description': parsed.get('æ¡ˆä»¶å†…å®¹', ''),  # ãƒªã‚¹ãƒˆã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›
                    # 'required_skills': ', '.join(parsed.get('å¿…é ˆã‚¹ã‚­ãƒ«', [])),  # ãƒªã‚¹ãƒˆã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›
                    # 'optional_skills': ', '.join(parsed.get('å°šå¯ã‚¹ã‚­ãƒ«', [])),  # ãƒªã‚¹ãƒˆã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›
                    'required_skills': parsed.get('å¿…é ˆã‚¹ã‚­ãƒ«', []),
                    'optional_skills': parsed.get('å°šå¯ã‚¹ã‚­ãƒ«', []),
                    "location": parsed.get("å‹¤å‹™åœ°", ""),
                    "unit_price": parsed.get("å˜ä¾¡", "") 
                }
                
                # å­˜å‚¨å¤„ç†åçš„æ•°æ®ï¼Œå‡†å¤‡å†™å…¥æ•°æ®åº“
                email_data_list.append(email_data)
            
            except Exception as e:
                logging.error(f"âŒ å¤„ç†é‚®ä»¶æ—¶å¤±è´¥: {str(e)}")
        
        # ç¬¬ä¸‰æ­¥ï¼šå°†æ•°æ®å†™å…¥æ•°æ®åº“
        if email_data_list:
            logging.info("ğŸ“¤ å¼€å§‹å†™å…¥æ•°æ®åº“...")
            for email_data in email_data_list:
                insert_email_to_db(email_data)
            logging.info("âœ… æ‰€æœ‰æ•°æ®å·²å­˜å…¥æ•°æ®åº“")
        
        # ç¬¬å››æ­¥ï¼šå°†æ•°æ®å¯¼å‡ºåˆ° Google Sheets
        if email_data_list:
            logging.info("ğŸ“Š å¼€å§‹å°†æ•°æ®å¯¼å‡ºåˆ°Google Sheets...")

            
            SPREADSHEET_ID = os.getenv("SPREADSHEET_ID")

            if not SPREADSHEET_ID:
                print("âŒ SPREADSHEET_ID æœªå®šä¹‰ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦æ­£ç¡®åŠ è½½")
            else:
                print(f"ğŸ”§ ä½¿ç”¨çš„ SPREADSHEET_ID: {SPREADSHEET_ID}")
                # ç¡®ä¿å°† SPREADSHEET_ID ä¼ é€’ç»™ export_to_sheet
                export_to_sheet(SPREADSHEET_ID)
            logging.info("âœ… æ•°æ®å·²æˆåŠŸå¯¼å‡ºåˆ° Google Sheets")

    except Exception as e:
        logging.error(f"ä¸»ç¨‹åºæ‰§è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()        



